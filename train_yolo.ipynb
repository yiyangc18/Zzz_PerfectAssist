{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来使用之前准备好的数据来训练一个yolo5模型，试试效果。首先把数据文件划分训练集、验证集、移到对应目录下。\n",
    "\n",
    "对了，之前在目录里面创建了虚拟环境，跑之前记得选择笔记本的python环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\24760\\\\Desktop\\\\Researches\\\\DRL\\\\Zzz_PerfectAssist'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "from config import CSV_FILE, IMAGE_DIR, LABEL_DIR, TRAIN_IMAGE_DIR, VAL_IMAGE_DIR, TRAIN_LABEL_DIR, VAL_LABEL_DIR\n",
    "from config import YOLOV5_DATA_CONFIG, YOLOV5_WEIGHTS, BATCH_SIZE, NUM_EPOCHS, LEARNING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建目标目录\n",
    "os.makedirs(TRAIN_IMAGE_DIR, exist_ok=True)\n",
    "os.makedirs(VAL_IMAGE_DIR, exist_ok=True)\n",
    "os.makedirs(TRAIN_LABEL_DIR, exist_ok=True)\n",
    "os.makedirs(VAL_LABEL_DIR, exist_ok=True)\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "# 只保留 gold_flash 和 red_flash 类别\n",
    "df = df[df['label'].isin(['gold_flash', 'red_flash'])]\n",
    "\n",
    "# 获取不同类别的图像文件\n",
    "class_0_images = df[df['label'] == 'gold_flash']['image'].tolist()\n",
    "class_1_images = df[df['label'] == 'red_flash']['image'].tolist()\n",
    "\n",
    "# 按 80/20 比例分为训练集和验证集\n",
    "def split_dataset(images):\n",
    "    random.shuffle(images)\n",
    "    split_index = int(len(images) * 0.8)\n",
    "    return images[:split_index], images[split_index:]\n",
    "\n",
    "train_class_0, val_class_0 = split_dataset(class_0_images)\n",
    "train_class_1, val_class_1 = split_dataset(class_1_images)\n",
    "\n",
    "# 合并训练集和验证集\n",
    "train_images = train_class_0 + train_class_1\n",
    "val_images = val_class_0 + val_class_1\n",
    "\n",
    "# 移动文件\n",
    "def move_files(image_list, source_image_dir, source_label_dir, target_image_dir, target_label_dir):\n",
    "    for image in image_list:\n",
    "        image_path = os.path.join(source_image_dir, image)\n",
    "        label_path = os.path.join(source_label_dir, os.path.splitext(image)[0] + '.txt')\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            shutil.copy(image_path, target_image_dir)\n",
    "            shutil.copy(label_path, target_label_dir)\n",
    "\n",
    "move_files(train_images, IMAGE_DIR, LABEL_DIR, TRAIN_IMAGE_DIR, TRAIN_LABEL_DIR)\n",
    "move_files(val_images, IMAGE_DIR, LABEL_DIR, VAL_IMAGE_DIR, VAL_LABEL_DIR)\n",
    "\n",
    "print(\"文件移动完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\24760\\Desktop\\Researches\\DRL\\Zzz_PerfectAssist\\yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\24760\\Desktop\\Researches\\DRL\\Zzz_PerfectAssist\\myenv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# %cp -r data/dataset yolo5/data\n",
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 定义标签目录\n",
    "label_dir = r'data\\\\dataset\\\\labels'\n",
    "\n",
    "# 映射关系\n",
    "label_mapping = {1: 0, 2: 1}\n",
    "\n",
    "# 遍历标签目录中的所有文件\n",
    "for subdir, _, files in os.walk(label_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            new_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.split()\n",
    "                class_id = int(parts[0])\n",
    "                if class_id in label_mapping:\n",
    "                    new_class_id = label_mapping[class_id]\n",
    "                    parts[0] = str(new_class_id)\n",
    "                    new_lines.append(' '.join(parts) + '\\n')\n",
    "                else:\n",
    "                    new_lines.append(line)  # 保留其他类的标注\n",
    "            \n",
    "            # 写入更新后的标签文件\n",
    "            with open(file_path, 'w') as f:\n",
    "                f.writelines(new_lines)\n",
    "\n",
    "print(\"标签更新完成。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集标签统计： {1: 13, 0: 54}\n",
      "验证集标签统计： {1: 4, 0: 14}\n",
      "没有找到标签2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 定义标签目录\n",
    "label_dir = r'data\\\\dataset\\\\labels'\n",
    "\n",
    "# 标签统计\n",
    "train_counts = {}\n",
    "val_counts = {}\n",
    "\n",
    "# 检查是否有标签2的存在\n",
    "has_class_2 = False\n",
    "\n",
    "# 遍历标签目录中的所有文件\n",
    "for subdir, _, files in os.walk(label_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            for line in lines:\n",
    "                parts = line.split()\n",
    "                class_id = int(parts[0])\n",
    "                \n",
    "                # 检查是否有标签2的存在\n",
    "                if class_id == 2:\n",
    "                    has_class_2 = True\n",
    "                    print(f\"标签2在文件 {file_path} 中找到\")\n",
    "\n",
    "                # 更新标签统计\n",
    "                if 'train' in subdir:\n",
    "                    if class_id not in train_counts:\n",
    "                        train_counts[class_id] = 0\n",
    "                    train_counts[class_id] += 1\n",
    "                elif 'val' in subdir:\n",
    "                    if class_id not in val_counts:\n",
    "                        val_counts[class_id] = 0\n",
    "                    val_counts[class_id] += 1\n",
    "\n",
    "# 打印标签统计信息\n",
    "print(\"训练集标签统计：\", train_counts)\n",
    "print(\"验证集标签统计：\", val_counts)\n",
    "\n",
    "if not has_class_2:\n",
    "    print(\"没有找到标签2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来可以训练了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import Image, display\n",
    "# 检查 GPU 是否可用\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开训！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 416 --batch-size {BATCH_SIZE} --epochs {NUM_EPOCHS} --data {YOLOV5_DATA_CONFIG} --weights {YOLOV5_WEIGHTS} --project runs/train --name exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看看日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在终端里面跑下面的命令。\n",
    "!tensorboard --logdir runs/train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
